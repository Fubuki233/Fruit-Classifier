{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26860a2",
   "metadata": {},
   "source": [
    "# Fruit Classifier - CNN Model\n",
    "\n",
    "This project uses Convolutional Neural Network (CNN) to classify fruit images:\n",
    "- Apple only\n",
    "- Orange only\n",
    "- Banana only\n",
    "- Mixed\n",
    "\n",
    "Target Accuracy: 92%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3b004",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56998362",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "\n",
    "**Important**: If you encounter NumPy import errors, run this cell to fix dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52dc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display TensorFlow and GPU information\n",
    "print(\"=\" * 60)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Keras version: {keras.__version__}\")\n",
    "\n",
    "# GPU Status\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\nGPU Status: {len(gpus)} GPU(s) available\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"  GPU {i}: {gpu.name}\")\n",
    "    \n",
    "    # Check GPU memory info (if available)\n",
    "    try:\n",
    "        gpu_details = tf.config.experimental.get_device_details(gpus[0])\n",
    "        if 'device_name' in gpu_details:\n",
    "            print(f\"  Device Name: {gpu_details['device_name']}\")\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"\\nGPU Status: Running on CPU\")\n",
    "    \n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb15e8",
   "metadata": {},
   "source": [
    "## 2. Setup Data Paths and Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a5fe8c",
   "metadata": {},
   "source": [
    "## 1.5. Data Synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c378d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "\n",
    "# original training directory\n",
    "# train_dir = '/home/zyh/Fruit-Classifier/data/train'\n",
    "\n",
    "train_dir = '/home/zyh/Fruit-Classifier/data/train_augment'\n",
    "\n",
    "test_dir = '/home/zyh/Fruit-Classifier/data/test'\n",
    "\n",
    "# Model parameters\n",
    "IMG_SIZE = 224  # Image size\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "NUM_CLASSES = 4  # apple_only, banana_only, orange_only, mixed\n",
    "\n",
    "# Class names\n",
    "class_names = ['apple_only', 'banana_only', 'mixed', 'orange_only']\n",
    "\n",
    "print(f\"Training data path: {train_dir}\")\n",
    "print(f\"Testing data path: {test_dir}\")\n",
    "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5821d9d",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daa5462",
   "metadata": {},
   "source": [
    "## 2.5. Organize Test Data (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8fd085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images in each class\n",
    "def count_images(directory):\n",
    "    counts = {}\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            num_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            counts[class_name] = num_images\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images(train_dir)\n",
    "test_counts = count_images(test_dir)\n",
    "\n",
    "print(\"Training set image counts:\")\n",
    "for class_name, count in sorted(train_counts.items()):\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "print(f\"  Total: {sum(train_counts.values())}\\n\")\n",
    "\n",
    "print(\"Test set image counts:\")\n",
    "for class_name, count in sorted(test_counts.items()):\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "print(f\"  Total: {sum(test_counts.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(train_counts, test_counts):\n",
    "    # Visualize class distribution\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Training set distribution\n",
    "    ax1.bar(train_counts.keys(), train_counts.values(), color='skyblue', edgecolor='navy')\n",
    "    ax1.set_title('Training Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Class')\n",
    "    ax1.set_ylabel('Number of Images')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Test set distribution\n",
    "    ax2.bar(test_counts.keys(), test_counts.values(), color='lightcoral', edgecolor='darkred')\n",
    "    ax2.set_title('Test Set Class Distribution', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Class')\n",
    "    ax2.set_ylabel('Number of Images')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_class_distribution(train_counts, test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79743157",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232b4733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def load_from_directory(directory):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        directory: path to data directory\n",
    "        \n",
    "    Returns:\n",
    "        dict with class names and image counts\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        raise ValueError(f\"Directory not found: {directory}\")\n",
    "    \n",
    "    data_info = {\n",
    "        'path': directory,\n",
    "        'classes': [],\n",
    "        'counts': {}\n",
    "    }\n",
    "    \n",
    "    for item in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, item)\n",
    "        if os.path.isdir(class_path):\n",
    "            images = [f for f in os.listdir(class_path) \n",
    "                     if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "            if images:\n",
    "                data_info['classes'].append(item)\n",
    "                data_info['counts'][item] = len(images)\n",
    "    \n",
    "    data_info['total'] = sum(data_info['counts'].values())\n",
    "    data_info['num_classes'] = len(data_info['classes'])\n",
    "    \n",
    "    return data_info\n",
    "\n",
    "\n",
    "def get_preprocessor(method='baseline', img_size=224, batch_size=32, train_dir=train_dir, test_dir=test_dir, val_split=0.2):\n",
    "    \"\"\"\n",
    "    Get data generators with different preprocessing methods\n",
    "    \n",
    "    Args:\n",
    "        method: 'baseline', 'light', 'heavy', 'moderate', 'minimal', 'color_boost', 'mixed'\n",
    "        img_size: image dimension (default 224)\n",
    "        batch_size: batch size for training (default 32)\n",
    "        train_dir: training data directory\n",
    "        test_dir: test data directory\n",
    "        val_split: validation split ratio (default 0.2)\n",
    "    \n",
    "    Returns:\n",
    "        train_gen, val_gen, test_gen\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'baseline':\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255, validation_split=val_split)\n",
    "        \n",
    "    elif method == 'light':\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=15,\n",
    "            horizontal_flip=True,\n",
    "            validation_split=val_split\n",
    "        )\n",
    "        \n",
    "    elif method == 'heavy':\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=30,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            brightness_range=[0.8, 1.2],\n",
    "            validation_split=val_split\n",
    "        )\n",
    "        \n",
    "    elif method == 'moderate':\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            validation_split=val_split\n",
    "        )\n",
    "        \n",
    "    elif method == 'minimal':\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=10,\n",
    "            zoom_range=0.1,\n",
    "            validation_split=val_split\n",
    "        )\n",
    "\n",
    "    elif method == 'heavy1':\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=45,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            validation_split=val_split\n",
    "        )\n",
    "\n",
    "    elif method == 'color_boost':\n",
    "        train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        zoom_range=0.15,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range=[0.7, 1.3],   # vary lighting\n",
    "        channel_shift_range=15.0,      # vary colors\n",
    "        validation_split=val_split\n",
    "    )\n",
    "        \n",
    "    elif method == 'mixed':\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.25,\n",
    "            height_shift_range=0.25,\n",
    "            shear_range=0.25,\n",
    "            zoom_range=0.35,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            brightness_range=[0.5, 1.5],\n",
    "            channel_shift_range=35.0,\n",
    "            fill_mode='nearest',\n",
    "            validation_split=val_split\n",
    "        )\n",
    "\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}. Choose from: baseline, light, heavy, moderate, minimal\")\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    val_gen = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    test_gen = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_gen, val_gen, test_gen\n",
    "\n",
    "\n",
    "def list_methods():\n",
    "    methods = {\n",
    "        'baseline': 'No augmentation, only rescaling',\n",
    "        'light': 'Rotation (15°) + Horizontal flip',\n",
    "        'heavy': 'Full augmentation (rotation, shift, zoom, shear, brightness, flips)',\n",
    "        'moderate': 'Balanced augmentation (rotation, shift, zoom, flip)',\n",
    "        'minimal': 'Minimal augmentation (slight rotation, zoom)',\n",
    "        'color_boost': 'Moderate geometry + brightness [0.7–1.3] + channel shift',\n",
    "        'mixed': 'intensive mix: strong geometry + brightness [0.5–1.5] + channel shift'\n",
    "\n",
    "    }\n",
    "    print(\"Available preprocessing methods:\")\n",
    "    for key, desc in methods.items():\n",
    "        print(f\"  - {key:12s}: {desc}\")\n",
    "    return methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator,validation_generator,test_generator = get_preprocessor(method='baseline', img_size=224, batch_size=32, train_dir=train_dir, test_dir=test_dir, val_split=0.2)\n",
    "\n",
    "\n",
    "print(f\"\\nTraining samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Test samples: {test_generator.samples}\")\n",
    "print(f\"\\nClass indices: {train_generator.class_indices}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e49d2f7",
   "metadata": {},
   "source": [
    "## 5. Build Basic CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    #Convolution blocks\n",
    "    model.add(layers.Conv2D(32, kernel_size = (3,3), \n",
    "                    padding='same',\n",
    "                    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                    activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2)) \n",
    "\n",
    "    model.add(layers.Conv2D(64, kernel_size = (3,3), \n",
    "                    padding='same',\n",
    "                    activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2)) \n",
    "\n",
    "    model.add(layers.Conv2D(128, kernel_size = (3,3), \n",
    "                    padding='same',\n",
    "                    activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=2))\n",
    "\n",
    "    #Classification layers\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(64,activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(32,activation='relu'))\n",
    "\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(NUM_CLASSES,activation='softmax'))\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_cnn_model()\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665e4849",
   "metadata": {},
   "source": [
    "## 6. Setup Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49705543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    # Early stopping: stop training if validation loss doesn't improve for 10 epochs\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Model checkpoint: save best model\n",
    "    ModelCheckpoint(\n",
    "        'best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Learning rate reduction: reduce LR if validation loss stops improving\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Callbacks configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b151dd",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ff2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"\\nTraining completed in {elapsed_time:.2f} seconds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710aa1f",
   "metadata": {},
   "source": [
    "## 8. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc424a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy and loss\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy curves\n",
    "ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss curves\n",
    "ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print best results\n",
    "best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "print(f\"\\nBest Epoch: {best_epoch + 1}\")\n",
    "print(f\"Best Validation Accuracy: {history.history['val_accuracy'][best_epoch]:.4f}\")\n",
    "print(f\"Corresponding Training Accuracy: {history.history['accuracy'][best_epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f24536",
   "metadata": {},
   "source": [
    "## 9. Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcccd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "# First check if test generator has samples\n",
    "if test_generator.samples == 0:\n",
    "    print(\"Warning: Test set is empty! Creating test generator again...\")\n",
    "    # Recreate test generator without shuffle to ensure proper loading\n",
    "    test_generator = test_generator.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    print(f\"Test samples loaded: {test_generator.samples}\")\n",
    "\n",
    "if test_generator.samples > 0:\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Check if target accuracy is reached\n",
    "    if test_accuracy >= 0.92:\n",
    "        print(f\"Congratulations! Target accuracy of 92% achieved!\")\n",
    "    else:\n",
    "        print(f\"Current accuracy {test_accuracy*100:.2f}% below 92% target, further optimization needed\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ERROR: No test images found!\")\n",
    "    print(f\"Please check the test directory: {test_dir}\")\n",
    "    print(\"Expected structure: test_dir/class_name/images.jpg\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba231e1",
   "metadata": {},
   "source": [
    "## 10. Generate Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c028ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Check if test set has samples before predicting\n",
    "if test_generator.samples == 0:\n",
    "    print(\"Cannot generate predictions: Test set is empty!\")\n",
    "    print(\"Please add test images to the test directory first.\")\n",
    "else:\n",
    "    # Reset test generator\n",
    "    test_generator.reset()\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(test_generator, verbose=1)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # True labels\n",
    "    y_true = test_generator.classes\n",
    "    \n",
    "    # Class labels\n",
    "    class_labels = list(test_generator.class_indices.keys())\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred_classes)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_labels, \n",
    "                yticklabels=class_labels,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Predicted Class', fontsize=12)\n",
    "    plt.ylabel('True Class', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(\"=\"*60)\n",
    "    print(classification_report(y_true, y_pred_classes, target_names=class_labels, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d529dbe0",
   "metadata": {},
   "source": [
    "## 11. Visualize Prediction Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dfbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display prediction samples\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def show_predictions(num_images=9):\n",
    "    \"\"\"Display prediction results\"\"\"\n",
    "    if test_generator.samples == 0:\n",
    "        print(\"Cannot show predictions: Test set is empty!\")\n",
    "        return\n",
    "    \n",
    "    # Reset test generator\n",
    "    test_generator.reset()\n",
    "    \n",
    "    # Get a batch of images\n",
    "    images, labels = next(test_generator)\n",
    "    predictions = model.predict(images[:num_images])\n",
    "    \n",
    "    # Plot\n",
    "    num_to_show = min(num_images, len(images))\n",
    "    rows = int(np.ceil(num_to_show / 3))\n",
    "    fig, axes = plt.subplots(rows, 3, figsize=(15, 5 * rows))\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_to_show):\n",
    "        axes[i].imshow(images[i])\n",
    "        \n",
    "        true_label = class_labels[np.argmax(labels[i])]\n",
    "        pred_label = class_labels[np.argmax(predictions[i])]\n",
    "        pred_prob = np.max(predictions[i]) * 100\n",
    "        \n",
    "        color = 'green' if true_label == pred_label else 'red'\n",
    "        axes[i].set_title(f'True: {true_label}\\nPredicted: {pred_label} ({pred_prob:.1f}%)',\n",
    "                         color=color, fontsize=10, fontweight='bold')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for i in range(num_to_show, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11525ccf",
   "metadata": {},
   "source": [
    "## 12. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model in native Keras format (recommended)\n",
    "model.save('fruit_classifier_cnn.keras')\n",
    "print(\"Model saved as 'fruit_classifier_cnn.keras' (Native Keras format)\")\n",
    "\n",
    "# Also save in HDF5 format for compatibility\n",
    "model.save('fruit_classifier_cnn.h5')\n",
    "print(\"Model saved as 'fruit_classifier_cnn.h5' (HDF5 format - legacy)\")\n",
    "# Export SavedModel for deployment (TFLite/TFServing)\n",
    "model.export('fruit_classifier_savedmodel')\n",
    "print(\"Model exported as 'fruit_classifier_savedmodel' (SavedModel for deployment)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Model Saving Summary:\")\n",
    "print(\"  • fruit_classifier_cnn.keras     - Native Keras (recommended)\")\n",
    "print(\"  • fruit_classifier_cnn.h5        - HDF5 (legacy compatibility)\")\n",
    "print(\"  • fruit_classifier_savedmodel/   - SavedModel (deployment)\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
