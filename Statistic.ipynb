{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic: 2 Convolutional Layers, Max Pooling, and 2 Fully Connected Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=3 (RGB), out_channels=16 filters\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16, out_channels=32 filters\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling: downsample by factor of 2\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected 1: input 7*7*32 -> output 128\n",
    "    self.fc1 = nn.Linear(in_features= 7 * 7 * 32, out_features=128)\n",
    "    \n",
    "    # Fully Connected 2: input 128 -> output 4 classes\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(-1, 7 * 7 * 32)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation, CrossEntropyLoss handles softmax)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  1.1 check the data for imbalances to prevent model bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = \"data/train\"\n",
    "\n",
    "# remove .DS_Store\n",
    "classes = [c for c in os.listdir(data_dir) \n",
    "           if os.path.isdir(os.path.join(data_dir, c))]\n",
    "\n",
    "class_counts = {\n",
    "    cls: len([f for f in os.listdir(os.path.join(data_dir, cls)) \n",
    "              if f.endswith('.jpg')])\n",
    "    for cls in classes\n",
    "}\n",
    "\n",
    "# ---- Plot ----\n",
    "plt.rcParams['font.family'] = 'sans-serif' \n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans'] # 优先使用 Arial\n",
    "\n",
    "# ---- Data preparation ----\n",
    "keys = list(class_counts.keys())\n",
    "values = list(class_counts.values())\n",
    "\n",
    "# ---- create convas ----\n",
    "fig, ax = plt.subplots(figsize=(9, 6), dpi=100) # dpi=100 让图片更清晰\n",
    "\n",
    "\n",
    "bars = ax.bar(keys, values, color='#4C72B0', width=0.6, zorder=3, alpha=0.9)\n",
    "\n",
    "# 1. Titles and axis labels\n",
    "ax.set_title(\"Class Distribution\", fontsize=16, fontweight='bold', pad=20, color='#333333')\n",
    "ax.set_xlabel(\"Class Name\", fontsize=12, labelpad=10, color='#555555')\n",
    "ax.set_ylabel(\"Count\", fontsize=12, labelpad=10, color='#555555')\n",
    "\n",
    "# 2. Grid lines: Only the horizontal grid along the y-axis is retained; dashed lines, light gray.\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.5, zorder=0)\n",
    "\n",
    "# 3. Remove unwanted borders (Spines)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False) \n",
    "ax.spines['bottom'].set_color('#CCCCCC') \n",
    "\n",
    "# 4. Scale processing\n",
    "ax.tick_params(axis='x', length=0) \n",
    "ax.tick_params(axis='y', length=0) \n",
    "\n",
    "# ----Add numbers to the table ----\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width() / 2, \n",
    "        height + (max(values) * 0.01), \n",
    "        f\"{int(height)}\", \n",
    "        ha='center', va='bottom', \n",
    "        fontsize=11, fontweight='bold', color='#4C72B0'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 split training data into train & valid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（To ensure that the train and value sets use completely different transforms, preventing the validation set from being \"enhanced and polluted,\"）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "#basic transform（for val / test）\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5]) #normalization\n",
    "])\n",
    "\n",
    "# build a ImageFolder with “no transform”，to split train/val\n",
    "base_dataset = datasets.ImageFolder(root=data_dir, transform=None)\n",
    "class_names = base_dataset.classes\n",
    "print(\"Classes:\", class_names)    # ['Apple', 'Banana', 'Mix', 'Orange'] \n",
    "\n",
    "# split training dataset 8/2\n",
    "val_ratio = 0.2\n",
    "num_total = len(base_dataset)\n",
    "num_val = int(num_total * val_ratio)\n",
    "num_train = num_total - num_val\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)   # random seed\n",
    "train_subset, val_subset = random_split(base_dataset, [num_train, num_val], generator=generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a \"wrapper Dataset\" to apply different transforms as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset          #  The Subset return from random_split\n",
    "        self.transform = transform    # Pass in the desired transforms.Compose\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.subset[idx]   #return image, label from base_dataset(original training)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a validation set (which remains constant across all experimental scenarios)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TransformedDataset(val_subset, base_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1 Baseline (no enhancements, unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练用的“无增强” transform\n",
    "train_transform_no_aug = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset_no_aug = TransformedDataset(train_subset, train_transform_no_aug)\n",
    "train_loader_no_aug = DataLoader(train_dataset_no_aug, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2 Unified lightweight enhancement (but still unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform_aug_all = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  #Flip horizontally (or left-right) with a 50% probability.\n",
    "    transforms.RandomRotation(degrees=15),  #Randomly rotate the image, ranging from -15° to +15°.\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), #Randomly change brightness, contrast, and saturation\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset_aug_all = TransformedDataset(train_subset, train_transform_aug_all)\n",
    "train_loader_aug_all = DataLoader(train_dataset_aug_all, batch_size=32, shuffle=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
